<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><title>GDG ML Papers</title><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Libre+Bodoni:ital,wght@0,400..700;1,400..700&family=UnifrakturMaguntia&display=swap" rel="stylesheet"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/gdg-ml-papers/_astro/ClientRouter.astro_astro_type_script_index_0_lang.CMTcOisY.js"></script><style>[data-astro-cid-kk57j3mo]{box-sizing:border-box}html{scroll-behavior:smooth;font-size:62.5%}body{background-color:#d9d9d9;color:#373737}.btn[data-astro-cid-kk57j3mo]{margin-top:32px;font-size:1.6rem;background-color:#373737;color:#d9d9d9;text-decoration:none;padding:12px 24px;border-radius:8px;cursor:pointer;transition:all .4s ease-in-out}.btn[data-astro-cid-kk57j3mo]:hover{background-color:#d9d9d9;color:#373737;border:2px solid black;box-shadow:0 6px 24px #0003;transition:all .6s ease-in-out}h1[data-astro-cid-kk57j3mo]{font-size:3rem;line-height:1;margin:12px 0}h2[data-astro-cid-kk57j3mo]{margin:50px 0 0;padding:0}h3[data-astro-cid-kk57j3mo]{font-family:UnifrakturMaguntia,cursive;color:#373737;font-size:1.8rem}a[data-astro-cid-kk57j3mo]{text-decoration:none}.container[data-astro-cid-kk57j3mo]{padding:2%}.content[data-astro-cid-kk57j3mo]{border:2px solid #6a6a6a;border-radius:4px;padding:2% 3%;font-size:1.8rem}code[data-astro-cid-kk57j3mo]{font-size:1.4rem;color:#6a6a6a;display:block}.resume[data-astro-cid-kk57j3mo]{margin-top:32px;padding-left:8px}
.astro-route-announcer{position:absolute;left:0;top:0;clip:rect(0 0 0 0);clip-path:inset(50%);overflow:hidden;white-space:nowrap;width:1px;height:1px}@keyframes astroFadeInOut{0%{opacity:1}to{opacity:0}}@keyframes astroFadeIn{0%{opacity:0;mix-blend-mode:plus-lighter}to{opacity:1;mix-blend-mode:plus-lighter}}@keyframes astroFadeOut{0%{opacity:1;mix-blend-mode:plus-lighter}to{opacity:0;mix-blend-mode:plus-lighter}}@keyframes astroSlideFromRight{0%{transform:translate(100%)}}@keyframes astroSlideFromLeft{0%{transform:translate(-100%)}}@keyframes astroSlideToRight{to{transform:translate(100%)}}@keyframes astroSlideToLeft{to{transform:translate(-100%)}}@media (prefers-reduced-motion){::view-transition-group(*),::view-transition-old(*),::view-transition-new(*){animation:none!important}[data-astro-transition-scope]{animation:none!important}}
</style><style>[data-astro-transition-scope="astro-yzcbpkil-1"] { view-transition-name: title-gradient-based-learning; }@layer astro { ::view-transition-old(title-gradient-based-learning) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }::view-transition-new(title-gradient-based-learning) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }[data-astro-transition=back]::view-transition-old(title-gradient-based-learning) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition=back]::view-transition-new(title-gradient-based-learning) { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; } }[data-astro-transition-fallback="old"] [data-astro-transition-scope="astro-yzcbpkil-1"],
			[data-astro-transition-fallback="old"][data-astro-transition-scope="astro-yzcbpkil-1"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition-fallback="new"] [data-astro-transition-scope="astro-yzcbpkil-1"],
			[data-astro-transition-fallback="new"][data-astro-transition-scope="astro-yzcbpkil-1"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }[data-astro-transition=back][data-astro-transition-fallback="old"] [data-astro-transition-scope="astro-yzcbpkil-1"],
			[data-astro-transition=back][data-astro-transition-fallback="old"][data-astro-transition-scope="astro-yzcbpkil-1"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeOut; }[data-astro-transition=back][data-astro-transition-fallback="new"] [data-astro-transition-scope="astro-yzcbpkil-1"],
			[data-astro-transition=back][data-astro-transition-fallback="new"][data-astro-transition-scope="astro-yzcbpkil-1"] { 
	animation-duration: 180ms;
	animation-timing-function: cubic-bezier(0.76, 0, 0.24, 1);
	animation-fill-mode: both;
	animation-name: astroFadeIn; }</style></head>   <div class="container" data-astro-cid-kk57j3mo> <a href="../../" data-astro-cid-kk57j3mo> <h3 data-astro-cid-kk57j3mo>Machine Learning Papers</h3> </a> <h1 data-astro-cid-kk57j3mo data-astro-transition-scope="astro-yzcbpkil-1">Gradient-based learning applied to document recognition</h1> <code data-astro-cid-kk57j3mo>Yann Lecun / Léon Bottou / Yoshua Bengio / Patrick Haffner</code> <a href="https://sci-hub.se/10.1109/5.726791" rel="noopener noreferrer" data-astro-cid-kk57j3mo> <button class="btn" data-astro-cid-kk57j3mo> <span data-astro-cid-kk57j3mo>Leer paper completo</span> </button> </a> <code class="resume" data-astro-cid-kk57j3mo>Resumen</code> <div class="content" data-astro-cid-kk57j3mo> <ol>
<li><strong>Uso de Redes Neuronales Convolucionales (CNNs)</strong></li>
</ol>
<p>Introducen una arquitectura llamada LeNet-5, una de las primeras CNNs diseñadas específicamente para el reconocimiento de caracteres escritos a mano (por ejemplo, en cheques bancarios).
LeNet-5 combina capas convolucionales, subsampling (o pooling) y capas completamente conectadas.</p>
<ol start="2">
<li><strong>Aprendizaje Basado en Gradientes</strong></li>
</ol>
<p>Utilizan descenso de gradiente estocástico (SGD) y retropropagación para entrenar la red de manera eficiente.
Argumentan que este método es más robusto y efectivo que los enfoques tradicionales de reconocimiento de patrones (como modelos basados en reglas o técnicas estadísticas clásicas).</p>
<ol start="3">
<li><strong>Aplicaciones al Reconocimiento de Documentos</strong></li>
</ol>
<p>Evalúan la efectividad de CNNs en la tarea de reconocimiento de caracteres en imágenes de documentos.
Comparan su método con otras técnicas clásicas como Máquinas de Vectores de Soporte (SVMs), Redes Bayesianas y Modelos de Mezcla Gaussiana.</p>
<ol start="4">
<li><strong>Ventajas de las CNNs</strong></li>
</ol>
<p>Invariancia a la traslación, escalado y deformaciones menores, gracias a la combinación de convoluciones y pooling.
Extracción automática de características, eliminando la necesidad de diseñar manualmente características para cada problema.
Escalabilidad y generalización, demostrando buenos resultados en conjuntos de datos reales.</p>
<p><strong>Impacto del Paper</strong></p>
<p>Este paper fue uno de los primeros en demostrar la viabilidad del aprendizaje profundo aplicado al reconocimiento de imágenes y documentos. Su enfoque sentó las bases para los avances en visión por computadora, OCR (reconocimiento óptico de caracteres) y más tarde, en la revolución del deep learning con redes profundas.</p> </div> </div>   <script type="module">
		import '@astro/client/hydration';
	</script> </html> 